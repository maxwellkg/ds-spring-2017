{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = pd.read_pickle('pickled_data.p')\n",
    "\n",
    "text_raw = [t for t in data['description']]\n",
    "\n",
    "#to lowercase\n",
    "text_lower = [s.lower() for s in text_raw]\n",
    "\n",
    "#remove any of below characters and replace with space - excesses will be removed later\n",
    "text_lower = [re.sub('[#!?*\";,())]',' ',s) for s in text_lower]\n",
    "\n",
    "#remove text artifacts\n",
    "text_lower = [re.sub('website_redacted',' ',s) for s in text_lower]\n",
    "text_lower = [re.sub('\\xa0',' ',s) for s in text_lower]\n",
    "text_lower = [re.sub('\\r','',s) for s in text_lower]\n",
    "text_lower = [re.sub('\\t','',s) for s in text_lower]\n",
    "text_lower = [re.sub('_',' ',s) for s in text_lower]\n",
    "\n",
    "# remove numbers of 3 or more digits as long as they are not preceded by a $\n",
    "# text_lower = [re.sub('(?<!([$]|\\d))\\d{3,}',' ',s) for s in text_lower]\n",
    "\n",
    "#remove $ only if it does not precede a number then remove all numbers\n",
    "text_lower = [re.sub('([$](?!\\d))',' ',s) for s in text_lower]\n",
    "text_lower = [re.sub('\\d{3,}',' ',s) for s in text_lower]\n",
    "text_lower = [re.sub('.00',' ',s) for s in text_lower]\n",
    "\n",
    "#remove below characters only if they are not preceded by a number\n",
    "text_lower = [re.sub('((?<!\\d)[.:-])',' ',s) for s in text_lower]\n",
    "\n",
    "#insert spaces between letters and numbers where \n",
    "text_lower = [re.sub(r'((?<=[a-z])\\d)',r' \\1',s) for s in text_lower]\n",
    "text_lower = [re.sub(r'(\\d(?=[a-z]))',r'\\1 ',s) for s in text_lower]\n",
    "\n",
    "#remove all html tags\n",
    "text_lower = [re.sub('(<.*?>)',' ',s) for s in text_lower]\n",
    "\n",
    "#replace ampersand with and\n",
    "text_lower = [re.sub('[&]',' and ',s) for s in text_lower]\n",
    "\n",
    "#replace w/ with \"with\"\n",
    "text_lower = [re.sub('w/',' with ',s) for s in text_lower]\n",
    "\n",
    "#replace / symbols with space\n",
    "text_lower = [re.sub('/',' ',s) for s in text_lower]\n",
    "\n",
    "#replace excess spaces\n",
    "text_lower = [re.sub(' +',' ',s).strip() for s in text_lower]\n",
    "\n",
    "#adjust important abbreviations\n",
    "text_lower = [re.sub(' br ',' bedroom ',s) for s in text_lower]\n",
    "text_lower = [re.sub('sq ft','square feet',s) for s in text_lower]\n",
    "text_lower = [re.sub(' ss ',' stainless steel',s) for s in text_lower]\n",
    "text_lower = [re.sub(' s s ',' staineless steel ',s) for s in text_lower]\n",
    "\n",
    "\n",
    "#remove trailing \"<a\"\n",
    "text_cleaned = [re.sub('<a','',s).strip() for s in text_lower]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data['cleantext'] = text_cleaned\n",
    "data.drop('description',axis=1)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['bathrooms', 'bedrooms', 'building_id', 'created', 'description',\n",
    "       'street_address', 'features', 'interest_level', 'latitude',\n",
    "       'listing_id', 'longitude', 'manager_id', 'photos'],axis=1)\n",
    "Y = data['interest_level'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Y[(Y=='low')]=1\n",
    "# Y[(Y=='medium')]=2\n",
    "# Y[(Y=='high')]=3\n",
    "# Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary_vectorizer = CountVectorizer(ngram_range=(2,2),binary=True,stop_words='english')\n",
    "binary_vectorizer = TfidfVectorizer(ngram_range=(1,2),stop_words='english')\n",
    "binary_vectorizer.fit(X['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(re.sub(r'(\\d(?=[a-z]))',r'\\1 ',text_cleaned[32756]))\n",
    "# m = re.search('00available',text_cleaned[32756])\n",
    "# text_raw[32756]\n",
    "# text_cleaned[8]\n",
    "# tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# tfidf_vectorizer.fit(X_train['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_vect = binary_vectorizer.transform(X_train['cleantext'])\n",
    "X_test_vect = binary_vectorizer.transform(X_test['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_bin = X_train.drop(['cleantext'],axis=1)\n",
    "X_train_bin['textvector'] = X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_tfidf_vector = tfidf_vectorizer.transform(X_train['cleantext'])\n",
    "# test_tfidf_vector = tfidf_vectorizer.transform(X_test['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train_tfidf = X_train\n",
    "# X_train_tfidf['textvector'] = train_tfidf_vector\n",
    "# X_train_tfidf.drop('cleantext',axis=1)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# l_model_tfidf = LogisticRegression()\n",
    "# l_model_tfidf.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# lr_param = {'C':[10**-i for i in range(-5,5)]}\n",
    "# lr_gscv = GridSearchCV(LogisticRegression(),lr_param,cv=10)\n",
    "# lr_gscv.fit(X_train_vect,Y_train)\n",
    "\n",
    "# print(str(lr_gscv.best_params_['C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_model_binary = LogisticRegression()\n",
    "l_model_binary.fit(X_train_vect, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predict = l_model_binary.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70489312126430959"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sum((test_predict!=Y_test)*1)/len(Y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
