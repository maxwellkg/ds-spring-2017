{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data_clean_text.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['bathrooms', 'latitude', 'longitude', 'building_id', 'created', 'street_address', 'description', 'display_address', 'features', 'listing_id', 'manager_id', 'photos', 'interest_level', 'neighborhood'],axis=1)\n",
    "Y = data['interest_level'].copy()\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Switch for selecting text or non text features\"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        if self.key=='text':\n",
    "            return data['cleantext']\n",
    "        else:\n",
    "            return data.drop('cleantext',axis=1)\n",
    "\n",
    "\n",
    "class VectorChooser(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Switch for choosing between vectorizers\"\"\"\n",
    "    def __init__(self, vtype='tfidf',binary=False,ngram_range=(1,1)):\n",
    "        self.vtype = vtype\n",
    "        self.tfidf = TfidfVectorizer(binary,ngram_range,stop_words='english')\n",
    "        self.count_vector = CountVectorizer(binary,ngram_range,stop_words='english')\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        if self.vtype=='tfidf':\n",
    "            return self.tfidf.fit(x)\n",
    "        else:\n",
    "            return self.count_vector.fit(x)\n",
    "\n",
    "    def transform(self, data):\n",
    "        if self.vtype=='tfidf':\n",
    "            return self.tfidf.transform(data)\n",
    "        else:\n",
    "            return self.count_vector.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    # Extract the subject & body\n",
    "\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text field\n",
    "            ('text', Pipeline([\n",
    "                ('selector', ItemSelector(key='text')),\n",
    "                ('vectorizer', VectorChooser()),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for K best selection of non-text features\n",
    "            ('alt_features', Pipeline([\n",
    "                ('selector', ItemSelector(key='features')),\n",
    "                ('kbest', SelectKBest())\n",
    "            ]))\n",
    "\n",
    "        ]\n",
    "    )),\n",
    "\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('logistic',LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [ 2  4 19] are constant.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(steps=[('selector', ItemSelector(key='text')), ('vectorizer', VectorChooser(binary=None, ngram_range=None, vtype='tfidf'))])), ('alt_features', Pipeline(steps=[('selector', ItemSelector(key='features')), ('kbest', Sel...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70104346064226208"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((pipeline.predict(X_test)==Y_test)/len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_vectorizer = TfidfVectorizer(ngram_range=(1,2),stop_words='english')\n",
    "binary_vectorizer.fit(X['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_vect = binary_vectorizer.transform(X_train['cleantext'])\n",
    "X_test_vect = binary_vectorizer.transform(X_test['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_bin = X_train.drop(['cleantext'],axis=1)\n",
    "data_coo = coo_matrix(X_train_bin.values,dtype=np.float64)\n",
    "X_train_data = hstack([data_coo,X_train_vect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_bin = X_test.drop(['cleantext'],axis=1)\n",
    "data_coo = coo_matrix(X_test_bin.values,dtype=np.float64)\n",
    "X_test_data = hstack([data_coo,X_test_vect])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
