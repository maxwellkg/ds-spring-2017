{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mord import LogisticAT\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data_clean_text.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data.drop(['bathrooms', 'latitude', 'longitude', 'building_id', 'created', 'street_address', 'description', 'display_address', 'features', 'listing_id', 'manager_id', 'photos', 'interest_level', 'neighborhood'],axis=1)\n",
    "Y = data['interest_level'].copy()\n",
    "\n",
    "Y = Y.replace(['low', 'medium', 'high'], [1,2,3])\n",
    "\n",
    "for column in X.columns.values:\n",
    "    if column == 'cleantext':\n",
    "        next\n",
    "    else:\n",
    "        if np.max(X[column])==0:\n",
    "            next\n",
    "        else:\n",
    "            X[column] = X[column]/np.max(X[column])\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Switch for selecting text or non text features\"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        if self.key=='text':\n",
    "            return data['cleantext']\n",
    "        else:\n",
    "            return data.drop('cleantext',axis=1)\n",
    "\n",
    "\n",
    "class VectorChooser(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Switch for choosing between vectorizers\"\"\"\n",
    "    def __init__(self, vtype='tfidf',binary=False,ngram_range=(1,1)):\n",
    "        self.vtype = vtype\n",
    "        self.tfidf = TfidfVectorizer(binary,ngram_range,stop_words='english')\n",
    "        self.count_vector = CountVectorizer(binary,ngram_range,stop_words='english')\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        if self.vtype=='tfidf':\n",
    "            return self.tfidf.fit(x)\n",
    "        else:\n",
    "            return self.count_vector.fit(x)\n",
    "\n",
    "    def transform(self, data):\n",
    "        if self.vtype=='tfidf':\n",
    "            return self.tfidf.transform(data)\n",
    "        else:\n",
    "            return self.count_vector.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['union', 'logistic']\n",
      "parameters:\n",
      "{'logistic__C': array([  1.00000000e-03,   1.00000000e-02,   1.00000000e-01,\n",
      "         1.00000000e+00,   1.00000000e+01,   1.00000000e+02]),\n",
      " 'logistic__solver': ['lbfgs'],\n",
      " 'union__text__vectorizer__binary': (True, False),\n",
      " 'union__text__vectorizer__ngram_range': ((1, 1), (1, 2), (2, 2))}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed: 15.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.357\n",
      "Best parameters set:\n",
      "\tlogistic__C: 10.0\n",
      "\tlogistic__solver: 'lbfgs'\n",
      "\tunion__text__vectorizer__binary: True\n",
      "\tunion__text__vectorizer__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text field\n",
    "            ('text', Pipeline([\n",
    "                ('selector', ItemSelector(key='text')),\n",
    "                ('vectorizer', VectorChooser(binary = True)),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for K best selection of non-text features\n",
    "            ('alt_features', Pipeline([\n",
    "                ('selector', ItemSelector(key='features')),\n",
    "                ('kbest', SelectKBest())\n",
    "            ]))\n",
    "\n",
    "        ]\n",
    "    )),\n",
    "\n",
    "    ('logistic', LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'logistic__solver': ['lbfgs'],\n",
    "    'union__text__vectorizer__ngram_range': ((1,1),(1,2),(2,2)),\n",
    "    'union__text__vectorizer__binary': (True, False),\n",
    "    'logistic__C': np.power(10.0, np.arange(-3,3))\n",
    "}\n",
    "\n",
    "#Grid search across one model\n",
    "grid_search = GridSearchCV(pipeline, parameters, verbose=1,scoring = 'mean_absolute_error')\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['union', 'randomforest']\n",
      "parameters:\n",
      "{'randomforest__min_samples_leaf': (10, 100, 1000),\n",
      " 'randomforest__min_samples_split': (1, 10, 100),\n",
      " 'union__text__vectorizer__binary': (True, False),\n",
      " 'union__text__vectorizer__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.379\n",
      "Best parameters set:\n",
      "\trandomforest__min_samples_leaf: 10\n",
      "\trandomforest__min_samples_split: 1\n",
      "\tunion__text__vectorizer__binary: True\n",
      "\tunion__text__vectorizer__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "pipeline = Pipeline([\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text field\n",
    "            ('text', Pipeline([\n",
    "                ('selector', ItemSelector(key='text')),\n",
    "                ('vectorizer', VectorChooser()),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for K best selection of non-text features\n",
    "            ('alt_features', Pipeline([\n",
    "                ('selector', ItemSelector(key='features')),\n",
    "                ('kbest', SelectKBest())\n",
    "            ]))\n",
    "\n",
    "        ]\n",
    "    )),\n",
    "\n",
    "    ('randomforest', RandomForestClassifier())\n",
    "])\n",
    "          \n",
    "parameters = {\n",
    "    'union__text__vectorizer__ngram_range': ((1,1),(1, 2)),\n",
    "    'union__text__vectorizer__binary': (True, False),\n",
    "    'randomforest__min_samples_split': (1,10,100),\n",
    "    'randomforest__min_samples_leaf': (10,100,1000),\n",
    "}\n",
    "\n",
    "#Grid search across one model\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring = 'mean_absolute_error')\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['union', 'nb']\n",
      "parameters:\n",
      "{'nb__alpha': array([  0.01,   0.1 ,   1.  ,  10.  ]),\n",
      " 'union__text__vectorizer__binary': (True, False),\n",
      " 'union__text__vectorizer__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.387\n",
      "Best parameters set:\n",
      "\tnb__alpha: 10.0\n",
      "\tunion__text__vectorizer__binary: True\n",
      "\tunion__text__vectorizer__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "pipeline = Pipeline([\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text field\n",
    "            ('text', Pipeline([\n",
    "                ('selector', ItemSelector(key='text')),\n",
    "                ('vectorizer', VectorChooser()),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for K best selection of non-text features\n",
    "            ('alt_features', Pipeline([\n",
    "                ('selector', ItemSelector(key='features')),\n",
    "                ('kbest', SelectKBest())\n",
    "            ]))\n",
    "\n",
    "        ]\n",
    "    )),\n",
    "\n",
    "    ('nb', BernoulliNB())\n",
    "])\n",
    "          \n",
    "parameters = {\n",
    "    'union__text__vectorizer__ngram_range': ((1,1),(1, 2)),\n",
    "    'union__text__vectorizer__binary': (True, False),\n",
    "    'nb__alpha': np.power(10.0, np.arange(-2,2)),\n",
    "}\n",
    "\n",
    "#Grid search across one model\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring = 'mean_absolute_error')\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['union', 'logisticat']\n",
      "parameters:\n",
      "{'union__text__vectorizer__ngram_range': ((1, 1), (2, 2)), 'union__alt_features__kbest__k': (10, 15, 20), 'logisticat__alpha': (0.001, 0.01, 0.1, 1, 10, 100), 'union__text__vectorizer__binary': (True, False)}\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    }
   ],
   "source": [
    "#Logistic AT\n",
    "pipeline = Pipeline([\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text field\n",
    "            ('text', Pipeline([\n",
    "                ('selector', ItemSelector(key='text')),\n",
    "                ('vectorizer', VectorChooser()),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for K best selection of non-text features\n",
    "            ('alt_features', Pipeline([\n",
    "                ('selector', ItemSelector(key='features')),\n",
    "                ('kbest', SelectKBest())\n",
    "            ]))\n",
    "\n",
    "        ]\n",
    "    )),\n",
    "\n",
    "    ('logisticat', LogisticAT(max_iter=250))\n",
    "])\n",
    "          \n",
    "parameters = {\n",
    "    'union__text__vectorizer__ngram_range': ((1,1),(2,2)),\n",
    "    'union__text__vectorizer__binary': (True, False),\n",
    "    'union__alt_features__kbest__k': (10, 15, 20),\n",
    "    'logisticat__alpha': (.001,.01,.1,1,10,100)\n",
    "}\n",
    "\n",
    "#Grid search across one model\n",
    "grid_search = GridSearchCV(pipeline, parameters, verbose=1, scoring = 'mean_absolute_error')\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['union', 'logisticat']\n",
      "parameters:\n",
      "{'union__text__vectorizer__ngram_range': ((1, 1), (1, 2), (2, 2)), 'union__alt_features__kbest__k': (10, 15, 20), 'union__text__vectorizer__vtype': ['count_vectorizer'], 'logisticat__alpha': (0.001, 0.01, 0.1, 1, 10, 100), 'union__text__vectorizer__binary': (True, False)}\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 324 out of 324 | elapsed: 51.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.348\n",
      "Best parameters set:\n",
      "\tlogisticat__alpha: 10\n",
      "\tunion__alt_features__kbest__k: 20\n",
      "\tunion__text__vectorizer__binary: True\n",
      "\tunion__text__vectorizer__ngram_range: (1, 1)\n",
      "\tunion__text__vectorizer__vtype: 'count_vectorizer'\n"
     ]
    }
   ],
   "source": [
    "#Logistic AT\n",
    "pipeline = Pipeline([\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text field\n",
    "            ('text', Pipeline([\n",
    "                ('selector', ItemSelector(key='text')),\n",
    "                ('vectorizer', VectorChooser()),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for K best selection of non-text features\n",
    "            ('alt_features', Pipeline([\n",
    "                ('selector', ItemSelector(key='features')),\n",
    "                ('kbest', SelectKBest())\n",
    "            ]))\n",
    "\n",
    "        ]\n",
    "    )),\n",
    "\n",
    "    ('logisticat', LogisticAT(max_iter=100))\n",
    "])\n",
    "          \n",
    "parameters = {\n",
    "    'union__text__vectorizer__ngram_range': ((1,1),(1,2),(2,2)),\n",
    "    'union__text__vectorizer__binary': (True, False),\n",
    "    'union__text__vectorizer__vtype': ['count_vectorizer'],\n",
    "    'union__alt_features__kbest__k': (10, 15, 20),\n",
    "    'logisticat__alpha': (.001,.01,.1,1,10,100)\n",
    "}\n",
    "\n",
    "#Grid search across one model\n",
    "grid_search = GridSearchCV(pipeline, parameters, verbose=1, scoring = 'mean_absolute_error')\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_vect = binary_vectorizer.transform(X_train['cleantext'])\n",
    "X_test_vect = binary_vectorizer.transform(X_test['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_bin = X_train.drop(['cleantext'],axis=1)\n",
    "data_coo = coo_matrix(X_train_bin.values,dtype=np.float64)\n",
    "X_train_data = hstack([data_coo,X_train_vect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_bin = X_test.drop(['cleantext'],axis=1)\n",
    "data_coo = coo_matrix(X_test_bin.values,dtype=np.float64)\n",
    "X_test_data = hstack([data_coo,X_test_vect])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
